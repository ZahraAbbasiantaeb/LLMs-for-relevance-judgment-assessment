{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "data_path = 'data/data.txt'\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "turn_score = defaultdict(lambda: defaultdict(list))\n",
    "all_scores = []\n",
    "for line in lines[1:]:\n",
    "    turn_id, user_utterance, response,  passage_id, passage_txt, score, ptkb, _ = line.split('\\t')\n",
    "    turn_score[turn_id][score].append(passage_id)\n",
    "    all_scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0', '4', '1', '2', '3'}\n"
     ]
    }
   ],
   "source": [
    "print(set(all_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 20457), ('1', 2787), ('2', 1803), ('3', 932), ('4', 179)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "res = list(Counter(all_scores).items())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_binary_count = defaultdict(lambda: defaultdict(int))\n",
    "turn_binary = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "\n",
    "for turn_id in turn_score:\n",
    "    for score in turn_score[turn_id]:\n",
    "        if int(score)>=2:\n",
    "            turn_binary_count[turn_id]['relevant'] += len(turn_score[turn_id][score])\n",
    "            turn_binary[turn_id]['relevant'] += turn_score[turn_id][score]\n",
    "        elif int(score)<2:    \n",
    "            turn_binary_count[turn_id]['irrelevant'] += len(turn_score[turn_id][score])\n",
    "            turn_binary[turn_id]['irrelevant'] += turn_score[turn_id][score]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_1 = 0\n",
    "for turn_id in turn_binary:\n",
    "    length_1 += len(turn_binary[turn_id]['relevant'])\n",
    "    length_1 += len(turn_binary[turn_id]['irrelevant'])\n",
    "print(length_1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "data_length = 0\n",
    "\n",
    "for turn_id in turn_binary:\n",
    "    turn_binary[turn_id]['irrelevant'] = random.choices(turn_binary[turn_id]['irrelevant'], k=len(turn_binary[turn_id]['relevant']))\n",
    "    print(turn_binary[turn_id]['relevant'])\n",
    "    print(turn_binary[turn_id]['irrelevant'])\n",
    "    print('\\n*****************\\n')\n",
    "    data_length += len(turn_binary[turn_id]['irrelevant']) + len(turn_binary[turn_id]['relevant'])\n",
    "\n",
    "\n",
    "print(data_length)    \n",
    "\n",
    "test_and_dev_size = int(data_length*0.3)\n",
    "print(test_and_dev_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=0\n",
    "\n",
    "validation_test_set = defaultdict(list)\n",
    "validation_set = defaultdict(list)\n",
    "\n",
    "for turn_id in turn_binary:\n",
    "    if len(turn_binary[turn_id]['relevant'])>1:\n",
    "        tmp = turn_binary[turn_id]['relevant'] + turn_binary[turn_id]['irrelevant']\n",
    "        length_tmp = len(tmp)\n",
    "        selected_passages = random.choices(tmp, k= int(length_tmp* 0.35) )\n",
    "        validation_test_set[turn_id] = selected_passages\n",
    "        \n",
    "        Y += len(selected_passages)\n",
    "\n",
    "        if len(selected_passages)>1:\n",
    "            validation_set[turn_id] = random.choices(selected_passages, k= int(len(selected_passages)* 0.5) )\n",
    "\n",
    "        \n",
    "        print(len(validation_test_set[turn_id]))\n",
    "        print(len(validation_set[turn_id]))\n",
    "        print('\\n*******************\\n')\n",
    "\n",
    "print(Y)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'NONE': 20680, 'train': 3852, 'validation': 709, 'test': 917})\n"
     ]
    }
   ],
   "source": [
    "count_label = defaultdict(int)\n",
    "all_new_lines = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "    lable = 'NONE'\n",
    "    turn_id, user_utterance, response,  passage_id, passage_txt, score, ptkb, _ = line.split('\\t')\n",
    "    if passage_id in validation_set[turn_id]:\n",
    "        lable = 'validation'\n",
    "    elif passage_id in validation_test_set[turn_id]:\n",
    "        lable = 'test'\n",
    "    elif (passage_id in turn_binary[turn_id]['relevant']):\n",
    "        lable = 'train'\n",
    "    elif (passage_id in turn_binary[turn_id]['irrelevant']):\n",
    "        lable = 'train'\n",
    "        \n",
    "    count_label[lable] += 1\n",
    "    new_line = '\\t'.join([turn_id, user_utterance, response,  passage_id, passage_txt, score, ptkb, lable])+'\\n'\n",
    "    all_new_lines.append(new_line)\n",
    "\n",
    "print(count_label)    \n",
    "\n",
    "\n",
    "with open('splitted_data.txt', 'w')    as f:\n",
    "    f.writelines(all_new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626\n",
      "0.2968236582694414\n",
      "5478\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = count_label['validation'] + count_label['test']\n",
    "y = count_label['train']\n",
    "print(n)\n",
    "print(n/(n+y))\n",
    "print(n+y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'splitted_data.txt'\n",
    "\n",
    "with open (file_name, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines: \n",
    "    turn_id, user_utterance, response,  passage_id, passage_txt, score, ptkb, lable = line.split('\\t')  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test', 'train', 'NONE', 'validation'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "file_path = \"path_to_file\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    df = pd.DataFrame(reader, columns=['turn_id', 'user_utterance', 'response',  'passage_id', 'passage_txt', 'score', 'ptkb', 'lable'])\n",
    "df.head()   \n",
    "\n",
    "print(set(list(df['lable'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test', 'train', 'NONE', 'validation'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "file_path = \"splitted_data.txt\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    df = pd.DataFrame(reader, columns=['turn_id', 'user_utterance', 'response',  'passage_id', 'passage_txt', 'score', 'ptkb', 'lable'])\n",
    "df.head()   \n",
    "\n",
    "print(set(list(df['lable'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['lable']=='test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['lable']=='train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['lable']=='validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20680\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['lable']=='NONE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
