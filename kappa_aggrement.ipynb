{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pool(paths):\n",
    "    pool_1 = defaultdict(int)\n",
    "\n",
    "    with open(paths, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        turn_id, _, passage_id, score = line.split('\\t')   \n",
    "        id = turn_id+'****'+ passage_id\n",
    "        pool_1[id] = int(score.strip())\n",
    "    return pool_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_kappa(path_gpt, path_nist):\n",
    "    gpt_pool = get_pool(path_gpt)\n",
    "    nist_pool = get_pool(path_nist)\n",
    "\n",
    "    gpt_label = []\n",
    "    nist_label = []\n",
    "    \n",
    "    for id in gpt_pool:\n",
    "        if id in nist_pool:\n",
    "            gpt_label.append(gpt_pool[id])\n",
    "            nist_label.append(nist_pool[id])\n",
    "\n",
    "    kappa_graded = cohen_kappa_score(gpt_label, nist_label)\n",
    "\n",
    "\n",
    "    gpt_binary = [0 if elem<2 else 1 for elem in gpt_label]\n",
    "    nist_binary = [0 if elem<2 else 1 for elem in nist_label]\n",
    "    \n",
    "    len(nist_binary)\n",
    "    len(gpt_binary)\n",
    "\n",
    "    kappa_binary = cohen_kappa_score(nist_binary, gpt_binary)\n",
    "    \n",
    "    return kappa_binary, kappa_graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_test_subset():\n",
    "    file_path = \"splitted_data.txt\"\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        df = pd.DataFrame(reader, columns=['turn_id', 'user_utterance', 'response',  'passage_id', 'passage_txt', 'score', 'ptkb', 'lable'])\n",
    "    df.head()   \n",
    "\n",
    "\n",
    "    test_set = df[df['lable']=='test']\n",
    "\n",
    "    turn_passages_test = []\n",
    "\n",
    "    for _, row in test_set.iterrows():\n",
    "        turn_passages_test.append(row[\"turn_id\"] +'****'+row[\"passage_id\"])\n",
    "    \n",
    "    return turn_passages_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_kappa_on_subset(path_gpt, path_nist):\n",
    "    gpt_pool = get_pool(path_gpt)\n",
    "    nist_pool = get_pool(path_nist)\n",
    "\n",
    "    subset = get_test_subset()\n",
    "    \n",
    "    gpt_label = []\n",
    "    nist_label = []\n",
    "    \n",
    "    for id in gpt_pool:\n",
    "        if id in subset:\n",
    "            gpt_label.append(gpt_pool[id])\n",
    "            nist_label.append(nist_pool[id])\n",
    "\n",
    "    kappa_graded = cohen_kappa_score(gpt_label, nist_label)\n",
    "\n",
    "\n",
    "    gpt_binary = [0 if elem<2 else 1 for elem in gpt_label]\n",
    "    nist_binary = [0 if elem<2 else 1 for elem in nist_label]\n",
    "    \n",
    "    len(nist_binary)\n",
    "    len(gpt_binary)\n",
    "\n",
    "    kappa_binary = cohen_kappa_score(nist_binary, gpt_binary)\n",
    "    \n",
    "    return kappa_binary, kappa_graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_nist = 'pools/human_qrels_tab'\n",
    "\n",
    "models_main_name = {'gpt3.5-one-shot-pool-V2': 'one-shot',\n",
    "                    'gpt3.5-one-shot-pool-V2-temp0': 'one-shot (tmp=0)',\n",
    "                    'gpt3.5-two-shot-pool' : 'two-shot',\n",
    "                    'gpt3.5-two-shot-pool-V2-temp0': 'two-shot (tmp=0)',\n",
    "                    'gpt3.5-zero-shot-pool':'zero-shot',\n",
    "                    'gpt3.5-zero-shot-paul-pool-temp0-': 'zero-shot (tmp=0)'\n",
    "                    }\n",
    "\n",
    "all_models_names = list(models_main_name.keys())\n",
    "\n",
    "for model_name in all_models_names:\n",
    "    path_gpt = 'outputs/'+model_name+'.txt'\n",
    "    kappa_binary, kappa_graded = report_kappa(path_gpt, path_nist)\n",
    "    print('{model_name} & {kappa_binary} & {kappa_graded} \\\\\\\\ \\\\midrule'.format(model_name = models_main_name[model_name], \n",
    "                                                                            kappa_binary=\"{:.3f}\".format(kappa_binary),\n",
    "                                                                            kappa_graded=\"{:.3f}\".format(kappa_graded)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_nist = 'pools/human_qrels_tab'\n",
    "\n",
    "\n",
    "models_main_name = {\n",
    "                    'gpt3.5-one-shot-pool-V2': 'one-shot',\n",
    "                    'gpt3.5-one-shot-pool-V2-temp0': 'one-shot (tmp=0)',\n",
    "                    'gpt3.5-two-shot-pool' : 'two-shot',\n",
    "                    'gpt3.5-two-shot-pool-V2-temp0': 'two-shot (tmp=0)',\n",
    "                    'gpt3.5-zero-shot-pool':'zero-shot',\n",
    "                    'gpt3.5-zero-shot-paul-pool-temp0-': 'zero-shot (tmp=0)',\n",
    "                    'Llama-3-FT-pool': 'Llama-3 FT',\n",
    "                    'Llama-3-inst-FT-pool': 'Llama-3-inst FT',\n",
    "                    'Llama-3-zero-pool': 'Llama-3 zero-shot',\n",
    "                    'Llama-3-inst-zero-pool': 'Llama-3-inst zero-shot'\n",
    "                    }\n",
    "\n",
    "all_models_names = list(models_main_name.keys())\n",
    "\n",
    "for model_name in all_models_names:\n",
    "    path_gpt = 'outputs/'+model_name+'.txt'\n",
    "    kappa_binary, kappa_graded = report_kappa_on_subset(path_gpt, path_nist)\n",
    "    print('{model_name} & {kappa_binary} & {kappa_graded} \\\\\\\\ \\\\midrule'.format(model_name = models_main_name[model_name], \n",
    "                                                                            kappa_binary=\"{:.3f}\".format(kappa_binary),\n",
    "                                                                            kappa_graded=\"{:.3f}\".format(kappa_graded)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
