# Using LLMs for Relevance judgment assessment
This repository contains the codes used in the following papers:
<a href="https://arxiv.org/pdf/2405.05600">Can We Use Large Language Models to Fill Relevance Judgment Holes?</a>
<a href="">Improving the Reusability of Conversational Search Test Collections.</a>

The scripts for using LLMs to generate relevance labels and evaluation of the generated labels are provided in this repo.
